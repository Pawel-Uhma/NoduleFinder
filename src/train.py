import os
import logging
from typing import List, Tuple, Optional

import torch
from torch.optim.lr_scheduler import StepLR
from tqdm import tqdm

from model import ModelFactory
from plots import (
    plot_loss,
    plot_map_accuracy,
    plot_iou_trend,
    plot_map_vs_iou,
)
from evaluate import evaluate_model, compute_coco_map

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Logging
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logger = logging.getLogger(__name__)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Trainer
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class Trainer:
    """Wrapper that handles the full training / validation / evaluation loop."""

    def __init__(self, model: torch.nn.Module, optimizer: torch.optim.Optimizer, device: torch.device):
        self.model = model
        self.optimizer = optimizer
        self.device = device

        # History containers â€“ guaranteed to have the same length (num_epochs)
        self.loss_history: List[float] = []
        self.val_loss_history: List[float] = []
        self.map_history: List[float] = []
        self.accuracy_history: List[float] = []
        self.mean_iou_history: List[float] = []

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Helpers
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _average_batch_loss(self, images, targets) -> torch.Tensor:
        """Compute total loss for a miniâ€‘batch returned by the detection model."""
        loss_dict = self.model(images, targets)
        total_loss = sum(v for v in loss_dict.values())
        return total_loss

    def _compute_validation_loss(self, dataloader) -> float:
        """Run a quick forward pass on the validation set and return mean loss."""
        self.model.eval()
        running_loss = 0.0
        with torch.no_grad():
            for images, targets in dataloader:
                images = [img.to(self.device) for img in images]
                targets = [
                    {
                        k: v.to(self.device) if isinstance(v, torch.Tensor) else v
                        for k, v in t.items()
                    }
                    for t in targets
                ]
                running_loss += self._average_batch_loss(images, targets).item()
        self.model.train()
        return running_loss / len(dataloader)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Public API
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def train(
        self,
        dataloader: torch.utils.data.DataLoader,
        num_epochs: int,
        scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None,
        eval_dataloader: Optional[torch.utils.data.DataLoader] = None,
        predictions_dir: str = "",  # forwarded to evaluate_model
        plots_dir: str = "./plots/",
        evaluate_each_epoch: bool = True,
    ) -> Tuple[List[float], List[float]]:
        """Main training loop.

        Args:
            dataloader: Training dataloader.
            num_epochs: Number of epochs.
            scheduler: Optional LR scheduler stepped once per epoch **after** all
                training / validation work is done.
            eval_dataloader: DataLoader used for metrics (IoU / mAP / etc.). If
                ``None``, no metrics or validation loss will be computed.
            predictions_dir: Passed straight through to ``evaluate_model`` â€“
                can stay empty if you do not save predictions.
            plots_dir: Destination folder for PNG plots.
            evaluate_each_epoch: If ``True`` compute detection metrics (IoU /
                mAP / TPâ€‘FPâ€‘FN) every epoch; otherwise compute them **once** at
                the very end. Validation *loss* is always computed each epoch
                because it is cheap and required for the twoâ€‘line loss plot.
        Returns:
            Tuple of (training_loss_history, validation_loss_history).
        """

        logger.info("ğŸš€ Starting training loop.")
        self.model.to(self.device)
        os.makedirs(plots_dir, exist_ok=True)

        # Preâ€‘declare to avoid UnboundLocalError when flag is False
        last_per_iou_map = None  # type: ignore
        last_metrics = None      # type: ignore

        for epoch in range(num_epochs):
            logger.info(f"ğŸ” Epoch {epoch + 1}/{num_epochs}")
            self.model.train()
            epoch_loss = 0.0

            # â”€â”€â”€â”€â”€â”€â”€ Training pass â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            for images, targets in tqdm(dataloader, desc=f"Epoch {epoch + 1}"):
                images = [img.to(self.device) for img in images]
                targets = [
                    {
                        k: v.to(self.device) if isinstance(v, torch.Tensor) else v
                        for k, v in t.items()
                    }
                    for t in targets
                ]

                total_loss = self._average_batch_loss(images, targets)
                self.optimizer.zero_grad()
                total_loss.backward()
                self.optimizer.step()

                epoch_loss += total_loss.item()

            avg_train_loss = epoch_loss / len(dataloader)
            self.loss_history.append(avg_train_loss)
            logger.info(f"ğŸ“‰ Training loss: {avg_train_loss:.4f}")

            # â”€â”€â”€â”€â”€â”€â”€ Validation loss (always) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if eval_dataloader is not None:
                avg_val_loss = self._compute_validation_loss(eval_dataloader)
                self.val_loss_history.append(avg_val_loss)
                logger.info(f"ğŸ“‰ Validation loss: {avg_val_loss:.4f}")
            else:
                # keep histories aligned
                self.val_loss_history.append(float('nan'))

            # â”€â”€â”€â”€â”€â”€â”€ Detection metrics (optional perâ€‘epoch) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if eval_dataloader is not None and evaluate_each_epoch:
                self.model.eval()
                last_metrics = evaluate_model(
                    self.model,
                    eval_dataloader,
                    self.device,
                    predictions_dir,
                    plots_dir,
                    save_predictions=False,
                    verbose=False,
                )
                self.mean_iou_history.append(last_metrics["mean_iou"])
                self.accuracy_history.append(last_metrics["accuracy"])
                self.map_history.append(last_metrics["mAP_50_95"])
                last_per_iou_map = last_metrics["per_iou_map"]
                self.model.train()
            else:
                # Maintain equalâ€‘length histories for plotting later.
                if eval_dataloader is not None:
                    self.mean_iou_history.append(float("nan"))
                    self.accuracy_history.append(float("nan"))
                    self.map_history.append(float("nan"))

            # â”€â”€â”€â”€â”€â”€â”€ Scheduler step (end of epoch) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if scheduler is not None:
                scheduler.step()

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        # Postâ€‘training final evaluation (if not done every epoch)        â”‚
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        if eval_dataloader is not None and not evaluate_each_epoch:
            last_metrics = evaluate_model(
                self.model,
                eval_dataloader,
                self.device,
                predictions_dir,
                plots_dir,
                save_predictions=False,
                verbose=True,  # Console prints TP / FP / FN during eval
            )
            last_per_iou_map = last_metrics["per_iou_map"]
            # Append *real* metrics for the final epoch position
            self.mean_iou_history[-1] = last_metrics["mean_iou"]
            self.accuracy_history[-1] = last_metrics["accuracy"]
            self.map_history[-1] = last_metrics["mAP_50_95"]

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        # Console summary                                                 â”‚
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        if last_metrics is not None:
            logger.info(
                f"TP: {last_metrics['TP']}  "
                f"FP: {last_metrics['FP']}  "
                f"FN: {last_metrics['FN']}"
            )
            for thr, ap in last_metrics["per_iou_map"].items():
                logger.info(f"AP@{thr:.2f}: {ap:.4f}")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        # Plots                                                          â”‚
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        plot_loss(self.loss_history, self.val_loss_history, dir=plots_dir)
        plot_map_accuracy(self.map_history, self.accuracy_history, dir=plots_dir)
        plot_iou_trend(self.mean_iou_history, dir=plots_dir)

        # The perâ€‘IoU mAP curve either comes from the last perâ€‘epoch eval or
        # from the final oneâ€‘off evaluation directly above.
        if eval_dataloader is not None and last_per_iou_map is None:
            # Compute it now only if truly missing.
            _, last_per_iou_map = compute_coco_map(
                self.model,
                eval_dataloader,
                self.device,
                iou_min=0.5,
                iou_max=0.95,
                iou_step=0.05,
                conf_thres=0.0,
            )
        if last_per_iou_map is not None:
            plot_map_vs_iou(last_per_iou_map, dir=plots_dir)

        return self.loss_history, self.val_loss_history


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Convenience helper â€“ train or load from file
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_or_train_model(
    model_file: str,
    num_classes: int,
    train_dataloader: torch.utils.data.DataLoader,
    eval_dataloader: Optional[torch.utils.data.DataLoader],
    device: torch.device,
    num_epochs: int,
    plots_dir: str,
    evaluate_each_epoch: bool = True,
) -> torch.nn.Module:
    """Load a saved model if it exists; otherwise train from scratch."""

    os.makedirs(os.path.dirname(model_file), exist_ok=True)

    if os.path.exists(model_file):
        logger.info("ğŸ“¦ Found saved model â€“ loading from disk â€¦")
        model = ModelFactory.get_model(num_classes)
        model.load_state_dict(torch.load(model_file, map_location=device))
        model.to(device)
        logger.info("âœ… Model loaded and moved to device")
        return model

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Train from scratch â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    logger.info("âŒ No saved model found â€“ starting fresh training â€¦")
    model = ModelFactory.get_model(num_classes)
    model.to(device)

    optimizer = torch.optim.SGD(
        model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005
    )
    scheduler = StepLR(optimizer, step_size=10, gamma=0.1)

    trainer = Trainer(model, optimizer, device)
    trainer.train(
        dataloader=train_dataloader,
        num_epochs=num_epochs,
        scheduler=scheduler,
        eval_dataloader=eval_dataloader,
        predictions_dir="",  # not saving predictions here
        plots_dir=plots_dir,
        evaluate_each_epoch=evaluate_each_epoch,
    )

    torch.save(model.state_dict(), model_file)
    logger.info(f"ğŸ’¾ Model trained and saved to: {model_file}")

    return model
